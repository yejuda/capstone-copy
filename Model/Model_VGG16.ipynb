{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJ7FeAlqw3nOELikfZHrJk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 드라이브 불러오기"],"metadata":{"id":"uNVofW_gfvaC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"obiHW2a1aBOd"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","source":["## 이미지 나누기 (train, val, test)"],"metadata":{"id":"H_OlAW8ofzLF"}},{"cell_type":"code","source":["!pip install split-folders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PL_7ozoraSbC","executionInfo":{"status":"ok","timestamp":1681201718102,"user_tz":-540,"elapsed":9366,"user":{"displayName":"이동언","userId":"14321894904846203384"}},"outputId":"b4c8f922-cf97-4476-dec9-5d0a411266c1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}]},{"cell_type":"code","source":["import splitfolders   # 입력된 비율을 기준으로 데이터셋을 분할하는 함수\n","input_folder = \"/content/drive/MyDrive/Capstone/모델링/이미지\"\n","output = \"/content/drive/MyDrive/Capstone/모델링/splited_image_LEE\" # where you want the split datasets saved. one will be created if it does not exist or none is set\n","\n","splitfolders.ratio(input_folder, output=output, seed=777, ratio=(.8, .1, .1)) # train,test를 8:2 split 후, train,val을 9:1로 split"],"metadata":{"id":"7_ySAgw0bczM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 이미지 파일이 아닌 경우 삭제 (오류 방지)"],"metadata":{"id":"u6gLMZTaf5AM"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","\n","dir_path = \"/content/drive/MyDrive/Capstone/모델링/splited_image_LEE\"\n","\n","# 모든 하위 폴더의 파일 탐색\n","for root, dirs, files in os.walk(dir_path):\n","    for file in files:\n","        try:\n","            # 이미지 파일인 경우에만 처리\n","            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n","                # 이미지 열기\n","                image_path = os.path.join(root, file)\n","                img = Image.open(image_path)\n","                img.verify()\n","        except (IOError, SyntaxError) as e:\n","            # 손상된 이미지 파일 삭제\n","            print(f\"Removing corrupted file: {image_path}\")\n","            os.remove(image_path)"],"metadata":{"id":"gKsoWrhgbn04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델링 (VGG16)"],"metadata":{"id":"yfzTG2Jof99Z"}},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","# 데이터 경로 설정\n","file_path = \"/content/drive/MyDrive/Capstone/모델링/splited_image_LEE\"\n","train_dir = os.path.join(file_path, 'train')\n","val_dir = os.path.join(file_path, 'val')\n","test_dir = os.path.join(file_path, 'test')\n","\n","# 이미지 데이터 전처리\n","train_datagen = ImageDataGenerator(rescale=1./255, \n","                                   rotation_range=20, \n","                                   width_shift_range=0.1, \n","                                   height_shift_range=0.1, \n","                                   shear_range=0.1, \n","                                   zoom_range=0.1, \n","                                   horizontal_flip=True, \n","                                   vertical_flip=True)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_dir, \n","                                                    target_size=(224, 224), \n","                                                    batch_size=32, \n","                                                    class_mode='categorical')\n","val_generator = val_datagen.flow_from_directory(val_dir, \n","                                                target_size=(224, 224), \n","                                                batch_size=32, \n","                                                class_mode='categorical')\n","test_generator = test_datagen.flow_from_directory(test_dir, \n","                                                   target_size=(224, 224), \n","                                                   batch_size=32, \n","                                                   class_mode='categorical')\n","\n","# VGG16 모델 로드하기\n","vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 새로운 분류 레이어 추가하기\n","x = vgg_model.output\n","x = Flatten()(x)\n","x = Dense(512, activation='relu')(x)\n","predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n","\n","# 새로운 모델 구성하기\n","model = Model(inputs=vgg_model.input, outputs=predictions)\n","\n","# 미세 조정(fine-tuning)을 위한 가중치 동결하기\n","for layer in vgg_model.layers:\n","    layer.trainable = False\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 학습\n","history = model.fit(train_generator, \n","                    epochs=10, \n","                    validation_data=val_generator)\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(test_generator)\n","print(\"Test accuracy:\", accuracy)\n","\n","# 모델 저장\n","model.save('/content/drive/MyDrive/Capstone/모델링/leecnn.h5')"],"metadata":{"id":"ikmL9GRxaJPA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 불러오기"],"metadata":{"id":"eTKWRo8cgDZV"}},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.imagenet_utils import decode_predictions\n","\n","from tensorflow.keras.models import load_model\n","\n","model = load_model('/content/drive/MyDrive/Capstone/모델링/leecnn.h5')"],"metadata":{"id":"SGdxh_THbyAl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 예측"],"metadata":{"id":"fKUkmpHMgJW6"}},{"cell_type":"code","source":["img_path = '/content/drive/MyDrive/Capstone/모델링/LEE_one/predict/만리장성2.jpg' # 예측하고자 하는 이미지 경로\n","target_size = (224, 224) # 모델이 학습시킨 이미지 사이즈와 동일하게 설정\n","\n","# 이미지 전처리\n","img = load_img(img_path, target_size=target_size)\n","x = img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = x / 255.0 # 이미지 스케일링\n","\n","# 예측\n","preds = model.predict(x)\n","\n","# 클래스별 확률 값 출력\n","class_indices = train_generator.class_indices\n","class_names = list(class_indices.keys())\n","\n","for i in range(len(class_names)):\n","  print(f\"{class_names[i]}: {round(preds[0][i]*100, 2)}%\")"],"metadata":{"id":"3yUF_KgDb0xz"},"execution_count":null,"outputs":[]}]}